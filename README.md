# ğŸ“ **README â€“ HÆ°á»›ng dáº«n cháº¡y dá»± Ã¡n House Price Prediction**

## ğŸ“Œ **Giá»›i thiá»‡u**

Dá»± Ã¡n nÃ y triá»ƒn khai má»™t pipeline khoa há»c dá»¯ liá»‡u hoÃ n chá»‰nh theo yÃªu cáº§u Ä‘á»“ Ã¡n mÃ´n *Python cho Khoa há»c Dá»¯ liá»‡u â€“ K23*, bao gá»“m:

* **Pháº§n 1:** Tiá»n xá»­ lÃ½ dá»¯ liá»‡u  
* **Pháº§n 2:** XÃ¢y dá»±ng vÃ  tá»‘i Æ°u mÃ´ hÃ¬nh há»c mÃ¡y  
* **Pháº§n 3:** Trá»±c quan hÃ³a & phÃ¢n tÃ­ch Ä‘áº·c trÆ°ng  

Dá»¯ liá»‡u sá»­ dá»¥ng: **Ames Housing Dataset** (táº­p train.csv vÃ  test.csv trong thÆ° má»¥c Data).

---

# ğŸ“ **Cáº¥u trÃºc thÆ° má»¥c**

```

house-prices-advanced-regression-techniques/
â”‚
â”œâ”€â”€ Code/
â”‚   â”œâ”€â”€ data_preprocessing.py       # Pháº§n 1 â€“ Tiá»n xá»­ lÃ½ (class DataPreprocessor)
â”‚   â”œâ”€â”€ eda_utils.py                # Pháº§n 3 â€“ EDA & phÃ¢n tÃ­ch Ä‘áº·c trÆ°ng
â”‚   â”œâ”€â”€ model_trainer.py            # Pháº§n 2 â€“ Huáº¥n luyá»‡n & tá»‘i Æ°u mÃ´ hÃ¬nh
â”‚   â””â”€â”€ main.py                     # Script cháº¡y chÃ­nh
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ train.csv                   # Dá»¯ liá»‡u huáº¥n luyá»‡n
â”‚   â”œâ”€â”€ test.csv                    # Dá»¯ liá»‡u test cá»§a Kaggle (optional)
â”‚   â”œâ”€â”€ sample_submission.csv       # File ná»™p Kaggle (optional)
â”‚   â””â”€â”€ data_description.txt        # MÃ´ táº£ biáº¿n
â”‚
â”œâ”€â”€ PythonProject_requirement.pdf   # File yÃªu cáº§u Ä‘á»“ Ã¡n
â”œâ”€â”€ README.md                       # HÆ°á»›ng dáº«n cháº¡y
â””â”€â”€ requirements.txt                # ThÆ° viá»‡n cáº§n cÃ i

````

---

# âš™ï¸ **1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng**

YÃªu cáº§u Python â‰¥ 3.8.

Cháº¡y:

```bash
pip install -r requirements.txt
````

Danh sÃ¡ch tá»‘i thiá»ƒu trong `requirements.txt`:

```
numpy
pandas
scikit-learn
optuna
joblib
matplotlib
seaborn
shap
lightgbm
xgboost
catboost
```

---

# ğŸš€ **2. Cháº¡y toÃ n bá»™ pipeline**

Cháº¡y file:

```bash
python main.py
```

Script tá»± Ä‘á»™ng thá»±c hiá»‡n:

1. Load dá»¯ liá»‡u tá»« thÆ° má»¥c **Data/**
2. Chia train/test
3. XÃ¢y dá»±ng pipeline tiá»n xá»­ lÃ½
4. Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh: Ridge, Lasso, ElasticNet, RandomForest, SVR
5. Tá»‘i Æ°u siÃªu tham sá»‘ báº±ng Optuna
6. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
7. Xuáº¥t káº¿t quáº£ + biá»ƒu Ä‘á»“
8. LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t dáº¡ng `.joblib`

---

# ğŸ§© **3. Cháº¡y tá»«ng pháº§n (náº¿u cáº§n)**

---

## ğŸ”¹ **3.1 Pháº§n 1 â€“ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**

```python
from data_preprocessing import DataPreprocessor

dp = DataPreprocessor(target_col="SalePrice")
df = dp.load_data("../Data/train.csv")

X, y = dp.split_features_target(df)

dp.build_feature_pipeline(X, X)
X_processed = dp.fit_transform_train(X, y)
```

---

## ğŸ”¹ **3.2 Pháº§n 2 â€“ Huáº¥n luyá»‡n mÃ´ hÃ¬nh**

```python
from model_trainer import ModelTrainer

trainer = ModelTrainer(
    target_col="SalePrice",
    test_size=0.2,
    random_state=42,
    output_dir="model_outputs"
)

trainer.run(
    csv_path="../Data/train.csv",
    tune_optuna=True     # chuyá»ƒn False náº¿u khÃ´ng muá»‘n cháº¡y tuning
)
```

Sau khi cháº¡y, thÆ° má»¥c `model_outputs/` sáº½ chá»©a:

* `model_results.csv` â€“ Báº£ng so sÃ¡nh RMSE / R2
* `rmse_comparison.png` â€“ Biá»ƒu Ä‘á»“ RMSE
* `training.log` â€“ Nháº­t kÃ½ huáº¥n luyá»‡n
* `*.joblib` â€“ MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (vÃ­ dá»¥: `random_forest_tuned.joblib`)

---

## ğŸ”¹ **3.3 Pháº§n 3 â€“ Trá»±c quan hÃ³a & phÃ¢n tÃ­ch mÃ´ hÃ¬nh**

```python
from eda_utils import EDAVisualizer
import pandas as pd

df = pd.read_csv("../Data/train.csv")

eda = EDAVisualizer(df, target_col="SalePrice", output_dir="eda_plots")

eda.plot_target_distribution()
eda.plot_missing_values()
eda.plot_numeric_histograms()
eda.plot_correlation_heatmap()
eda.plot_boxplots_for_top_categories("Neighborhood")
```

### ğŸ”¸ Feature importance / SHAP / PDP

```python
from eda_utils import (
    plot_feature_importance_from_model,
    plot_permutation_importance,
    plot_shap_summary,
    plot_partial_dependence_for_features
)

model = trainer.models_["random_forest"]  # vÃ­ dá»¥

plot_feature_importance_from_model(
    model,
    feature_names=[f"f{i}" for i in range(200)],
    output_path="eda_plots/importance.png"
)

plot_shap_summary(
    model,
    trainer.X_train_,
    output_dir="eda_plots"
)
```

---

# ğŸ“Š **4. CÃ¡c file output quan trá»ng**

### ğŸ“‚ `model_outputs/`

* `model_results.csv`
* `rmse_comparison.png`
* `training.log`
* `*.joblib`

### ğŸ“‚ `eda_plots/`

* `target_distribution.png`
* `missing_values_fraction.png`
* `numeric_histograms.png`
* `correlation_heatmap_subset.png`
* `boxplot_SalePrice_by_Neighborhood.png`
* `importance.png`
* `shap_summary.png`

---

# ğŸ’¡ **5. TÃ¹y chá»‰nh khi cháº¡y**

CÃ³ thá»ƒ chá»‰nh trong `main.py`:

* `test_size`
* `random_state`
* danh sÃ¡ch mÃ´ hÃ¬nh cáº§n train
* báº­t / táº¯t Optuna
* thÃªm GridSearchCV
* thÃªm model má»›i nhÆ° LightGBM, CatBoost, XGBoost

---

# ğŸ“ **6. Phá»¥c vá»¥ bÃ¡o cÃ¡o**

Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c káº¿t quáº£ sau:

* Báº£ng sá»‘ liá»‡u: `model_results.csv`
* Biá»ƒu Ä‘á»“ RMSE: `rmse_comparison.png`
* Biá»ƒu Ä‘á»“ EDA: `eda_plots/*`
* Nháº­t kÃ½ huáº¥n luyá»‡n: `training.log`
* SÆ¡ Ä‘á»“ pipeline mÃ´ táº£ DataPreprocessor & ModelTrainer

---

# âœ”ï¸ **7. Káº¿t luáº­n**

Project hoÃ n chá»‰nh theo Ä‘Ãºng yÃªu cáº§u Ä‘á»“ Ã¡n:

* **Pháº§n 1:** Tiá»n xá»­ lÃ½ dá»¯ liá»‡u vá»›i `DataPreprocessor`
* **Pháº§n 2:** Huáº¥n luyá»‡n & tá»‘i Æ°u mÃ´ hÃ¬nh vá»›i `ModelTrainer`
* **Pháº§n 3:** Trá»±c quan hÃ³a & giáº£i thÃ­ch mÃ´ hÃ¬nh vá»›i `EDAVisualizer`

Cáº¥u trÃºc rÃµ rÃ ng, dá»… má»Ÿ rá»™ng vÃ  dá»… tÃ¡i sá»­ dá»¥ng cho cÃ¡c bÃ i toÃ¡n dá»± Ä‘oÃ¡n tÆ°Æ¡ng tá»±.
